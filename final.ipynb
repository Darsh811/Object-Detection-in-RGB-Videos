{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T08:33:54.103044Z","iopub.execute_input":"2023-04-21T08:33:54.103515Z","iopub.status.idle":"2023-04-21T08:33:54.133429Z","shell.execute_reply.started":"2023-04-21T08:33:54.103479Z","shell.execute_reply":"2023-04-21T08:33:54.132493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:54.135283Z","iopub.execute_input":"2023-04-21T08:33:54.135659Z","iopub.status.idle":"2023-04-21T08:33:54.291269Z","shell.execute_reply.started":"2023-04-21T08:33:54.135623Z","shell.execute_reply":"2023-04-21T08:33:54.29013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cap =cv2.VideoCapture('/kaggle/input/samplepesu/Training Dataset_Videos/V_AIRPLANE_001.mp4')\nret ,img = cap.read()\nprint(f'Returned {ret} and img of shape {img.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:54.293187Z","iopub.execute_input":"2023-04-21T08:33:54.293792Z","iopub.status.idle":"2023-04-21T08:33:54.381007Z","shell.execute_reply.started":"2023-04-21T08:33:54.293754Z","shell.execute_reply":"2023-04-21T08:33:54.380014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:54.382197Z","iopub.execute_input":"2023-04-21T08:33:54.383565Z","iopub.status.idle":"2023-04-21T08:33:54.711026Z","shell.execute_reply.started":"2023-04-21T08:33:54.383524Z","shell.execute_reply":"2023-04-21T08:33:54.709999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Helper function for plotting opencv images in notebook\ndef display_cv2_img(img, figsize=(10, 10)):\n    img_ = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.imshow(img_)\n    ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:54.713827Z","iopub.execute_input":"2023-04-21T08:33:54.714185Z","iopub.status.idle":"2023-04-21T08:33:54.720469Z","shell.execute_reply.started":"2023-04-21T08:33:54.714147Z","shell.execute_reply":"2023-04-21T08:33:54.718739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_cv2_img(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:54.721849Z","iopub.execute_input":"2023-04-21T08:33:54.722299Z","iopub.status.idle":"2023-04-21T08:33:55.106546Z","shell.execute_reply.started":"2023-04-21T08:33:54.722263Z","shell.execute_reply":"2023-04-21T08:33:55.105483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cap.release()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:55.10803Z","iopub.execute_input":"2023-04-21T08:33:55.108677Z","iopub.status.idle":"2023-04-21T08:33:55.117091Z","shell.execute_reply.started":"2023-04-21T08:33:55.108633Z","shell.execute_reply":"2023-04-21T08:33:55.115989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working/test'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)'''\nimport os \nos.makedirs('/kaggle/working/test')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:55.11866Z","iopub.execute_input":"2023-04-21T08:33:55.119123Z","iopub.status.idle":"2023-04-21T08:33:55.125287Z","shell.execute_reply.started":"2023-04-21T08:33:55.119086Z","shell.execute_reply":"2023-04-21T08:33:55.124182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = \"/kaggle/input/samplepesu/Training Dataset_Videos\"\n\nfor filename in os.listdir(directory):\n    filepath = os.path.join(directory, filename)\n    \nFileNames = os.listdir(directory)\nFileNames2 = sorted(os.listdir(directory))\nprint(FileNames2)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:55.126945Z","iopub.execute_input":"2023-04-21T08:33:55.127492Z","iopub.status.idle":"2023-04-21T08:33:55.238784Z","shell.execute_reply.started":"2023-04-21T08:33:55.1274Z","shell.execute_reply":"2023-04-21T08:33:55.237704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_count = 0\nfor filename in FileNames2:\n    filepath = os.path.join(directory, filename)\n    print(filepath)\n    path = filepath.split(\"\\n\")\n    print(path[0])\n    cap =cv2.VideoCapture(path[0])\n    local_count = 0\n    n_frames = int(cap.get(cv2.cv2.CAP_PROP_FRAME_COUNT))\n    print('Number of Frames', n_frames)\n    for frame in range(n_frames):\n        ret, img = cap.read()\n        count=float(str(cap.get(cv2.CAP_PROP_POS_MSEC)))\n        cv2.imwrite(\"/kaggle/working/test/%d.jpg\" % global_count, img )\n        global_count = global_count + 1\n        local_count = local_count + 1\n    print('Total Number of Images', global_count)\n    print('Number of frames in current video', local_count)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:33:57.299151Z","iopub.execute_input":"2023-04-21T08:33:57.299876Z","iopub.status.idle":"2023-04-21T08:41:39.898674Z","shell.execute_reply.started":"2023-04-21T08:33:57.299835Z","shell.execute_reply":"2023-04-21T08:41:39.897391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = \"/kaggle/input/samplepesu/Training Dataset_csv\"\n\nfor filename in os.listdir(directory):\n    filepath = os.path.join(directory, filename)\n    \nFileNames = os.listdir(directory)\nFileNames2 = sorted(os.listdir(directory))\nprint(FileNames2)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:39.900526Z","iopub.execute_input":"2023-04-21T08:41:39.900841Z","iopub.status.idle":"2023-04-21T08:41:39.985472Z","shell.execute_reply.started":"2023-04-21T08:41:39.900811Z","shell.execute_reply":"2023-04-21T08:41:39.984283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\nfor filename in FileNames2:\n    filepath = os.path.join(directory, filename)\n    print(filepath)\n    data = pd.read_csv(str(filepath), header = None)\n    df = pd.concat([df, data], axis = 0)\ndf.to_csv(\"AllLabels.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:39.986814Z","iopub.execute_input":"2023-04-21T08:41:39.987263Z","iopub.status.idle":"2023-04-21T08:41:43.039598Z","shell.execute_reply.started":"2023-04-21T08:41:39.987224Z","shell.execute_reply":"2023-04-21T08:41:43.038545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/alllabels/AllLabels.csv\")\ndata = []\n#18272\n#print(df.iloc[0][1].strip('[]').split(\",\"))\nfor Index in range(0, 18273):\n    L = df.iloc[Index][1].strip('[]').split(\",\")\n    if(len(L) > 4):\n        M = L[3].split(\";\")\n        L[3] = M[0]\n    #print(L, Index)\n    data.append(\n            {\n                'TimeStamp': df.iloc[Index][0],\n                'Label': \"1\",\n                'XMin': float(L[0]),\n                'YMin': float(L[1]),\n                'XMax': float(L[0]) + float(L[2]),\n                'YMax': float(L[1]) + float(L[3])\n            }\n    )\n\nfor Index in range(18273, 34063):\n    L = df.iloc[Index][2].strip('[]').split(\",\")\n    if(len(L) > 4):\n        M = L[3].split(\";\")\n        L[3] = M[0]\n    if(len(L) == 1):\n        L = [0, 0, 0, 0]\n    #print(L, Index, len(L))\n    data.append(\n            {\n                'TimeStamp': df.iloc[Index][0],\n                'Label': \"2\",\n                'XMin': float(L[0]),\n                'YMin': float(L[1]),\n                'XMax': float(L[0]) + float(L[2]),\n                'YMax': float(L[1]) + float(L[3])\n            }\n    )\n    \nfor Index in range(34063, 68926):\n    L = df.iloc[Index][3].strip('[]').split(\",\")\n    if(len(L) > 4):\n        M = L[3].split(\";\")\n        L[3] = M[0]\n    data.append(\n            {\n                'TimeStamp': df.iloc[Index][0],\n                'Label': \"3\",\n                'XMin': float(L[0]),\n                'YMin': float(L[1]),\n                'XMax': float(L[0]) + float(L[2]),\n                'YMax': float(L[1]) + float(L[3])\n            }\n    )\n\nfor Index in range(68926, 87645):\n    L = df.iloc[Index][4].strip('[]').split(\",\")\n    if(len(L) > 4):\n        M = L[3].split(\";\")\n        L[3] = M[0]\n    #print(L, Index)\n    if(len(L) == 1):\n        L = [0, 0, 0, 0]\n    data.append(\n            {\n                'TimeStamp': df.iloc[Index][0],\n                'Label': \"4\",\n                'XMin': float(L[0]),\n                'YMin': float(L[1]),\n                'XMax': float(L[0]) + float(L[2]),\n                'YMax': float(L[1]) + float(L[3])\n            }\n    )\n\ndf2 = pd.DataFrame(data)\nprint(df2)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:43.042325Z","iopub.execute_input":"2023-04-21T08:41:43.042628Z","iopub.status.idle":"2023-04-21T08:41:53.228833Z","shell.execute_reply.started":"2023-04-21T08:41:43.0426Z","shell.execute_reply":"2023-04-21T08:41:53.227639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory = \"/kaggle/working/test/\"\n\nfor filename in os.listdir(directory):\n    filepath = os.path.join(directory, filename)\n    \nFileNames = os.listdir(directory)\nFileNames2 = sorted(os.listdir(directory))\nprint(FileNames2)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.230391Z","iopub.execute_input":"2023-04-21T08:41:53.23117Z","iopub.status.idle":"2023-04-21T08:41:53.518721Z","shell.execute_reply.started":"2023-04-21T08:41:53.231126Z","shell.execute_reply":"2023-04-21T08:41:53.517777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Path1 = []\nFiles = []\ncount = 0\nfor filename in FileNames2:\n    S = filename.split(\".\")\n    filepath = os.path.join(directory, filename)\n    path = filepath.split(\"\\n\")\n    Path1.append(count)\n    Files.append(count)\n    count = count + 1\nPath2 = sorted(Path1)\nPath3 = []\nfor i in Path2:\n    Path3.append(directory + str(i) + \".jpg\")\n#print(Path3)\nPath4 = []\nfor i in Path2:\n    Path4.append(str(i) + \".jpg\")\ndf2['ImagePath'] = Path3\ndf2['ImageID'] = Path4\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.519914Z","iopub.execute_input":"2023-04-21T08:41:53.521077Z","iopub.status.idle":"2023-04-21T08:41:53.821405Z","shell.execute_reply.started":"2023-04-21T08:41:53.52104Z","shell.execute_reply":"2023-04-21T08:41:53.819337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_drop=range(1000,10000)\ndf3=df2.drop(range_drop)\ndf3\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.822914Z","iopub.execute_input":"2023-04-21T08:41:53.82403Z","iopub.status.idle":"2023-04-21T08:41:53.872708Z","shell.execute_reply.started":"2023-04-21T08:41:53.823988Z","shell.execute_reply":"2023-04-21T08:41:53.871388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_drop=range(19000,26000)\ndf4=df3.drop(range_drop)\ndf4","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.874627Z","iopub.execute_input":"2023-04-21T08:41:53.875003Z","iopub.status.idle":"2023-04-21T08:41:53.906983Z","shell.execute_reply.started":"2023-04-21T08:41:53.874966Z","shell.execute_reply":"2023-04-21T08:41:53.906052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_drop=range(50000,57000)\ndf5=df4.drop(range_drop)\ndf5","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.908462Z","iopub.execute_input":"2023-04-21T08:41:53.91044Z","iopub.status.idle":"2023-04-21T08:41:53.941283Z","shell.execute_reply.started":"2023-04-21T08:41:53.910397Z","shell.execute_reply":"2023-04-21T08:41:53.940226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_drop=range(70000,80000)\ndf6=df5.drop(range_drop)\ndf6","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.946086Z","iopub.execute_input":"2023-04-21T08:41:53.946395Z","iopub.status.idle":"2023-04-21T08:41:53.975019Z","shell.execute_reply.started":"2023-04-21T08:41:53.946367Z","shell.execute_reply":"2023-04-21T08:41:53.973788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df6['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.976439Z","iopub.execute_input":"2023-04-21T08:41:53.977562Z","iopub.status.idle":"2023-04-21T08:41:53.99158Z","shell.execute_reply.started":"2023-04-21T08:41:53.977522Z","shell.execute_reply":"2023-04-21T08:41:53.990265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_drop=range(35000,50000)\ndf7=df6.drop(range_drop)\ndf7","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:53.993481Z","iopub.execute_input":"2023-04-21T08:41:53.993958Z","iopub.status.idle":"2023-04-21T08:41:54.021779Z","shell.execute_reply.started":"2023-04-21T08:41:53.993918Z","shell.execute_reply":"2023-04-21T08:41:54.020499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df7['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.023659Z","iopub.execute_input":"2023-04-21T08:41:54.024044Z","iopub.status.idle":"2023-04-21T08:41:54.034617Z","shell.execute_reply.started":"2023-04-21T08:41:54.024001Z","shell.execute_reply":"2023-04-21T08:41:54.033395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"types = df7.dtypes\ntypes","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.036522Z","iopub.execute_input":"2023-04-21T08:41:54.037093Z","iopub.status.idle":"2023-04-21T08:41:54.04693Z","shell.execute_reply.started":"2023-04-21T08:41:54.037052Z","shell.execute_reply":"2023-04-21T08:41:54.045658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df7[\"Label\"]=df7[\"Label\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.048871Z","iopub.execute_input":"2023-04-21T08:41:54.049573Z","iopub.status.idle":"2023-04-21T08:41:54.062391Z","shell.execute_reply.started":"2023-04-21T08:41:54.049536Z","shell.execute_reply":"2023-04-21T08:41:54.061181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"types = df7.dtypes\ntypes","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.064088Z","iopub.execute_input":"2023-04-21T08:41:54.064791Z","iopub.status.idle":"2023-04-21T08:41:54.072508Z","shell.execute_reply.started":"2023-04-21T08:41:54.064754Z","shell.execute_reply":"2023-04-21T08:41:54.071552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove .jpg extension from image_id \ndf7['ImgID'] = df7['ImageID'].apply(lambda x:x.split('.')).map(lambda x:x[0])\ndf7.drop(columns=['ImageID'], inplace=True)\ndf7","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.074746Z","iopub.execute_input":"2023-04-21T08:41:54.075667Z","iopub.status.idle":"2023-04-21T08:41:54.141371Z","shell.execute_reply.started":"2023-04-21T08:41:54.07562Z","shell.execute_reply":"2023-04-21T08:41:54.140137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df8 = df7[180.0 <= df7['YMax']]\ndf8","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.143473Z","iopub.execute_input":"2023-04-21T08:41:54.1439Z","iopub.status.idle":"2023-04-21T08:41:54.166047Z","shell.execute_reply.started":"2023-04-21T08:41:54.143857Z","shell.execute_reply":"2023-04-21T08:41:54.164988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9 = df8[df8['YMax'] <= 380]\ndf9","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.16774Z","iopub.execute_input":"2023-04-21T08:41:54.168102Z","iopub.status.idle":"2023-04-21T08:41:54.190252Z","shell.execute_reply.started":"2023-04-21T08:41:54.168065Z","shell.execute_reply":"2023-04-21T08:41:54.189111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q albumentations\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport os\nfrom albumentations import RandomRotate90\nfrom tensorflow.keras import mixed_precision\nimport gc\nimport os\nimport collections\nimport pandas as pd\nimport numpy as np\nimport functools\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom sklearn import preprocessing \n\n\nimport xml.etree.ElementTree as ET\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data import SequentialSampler\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:41:54.192063Z","iopub.execute_input":"2023-04-21T08:41:54.192434Z","iopub.status.idle":"2023-04-21T08:42:15.427118Z","shell.execute_reply.started":"2023-04-21T08:41:54.192399Z","shell.execute_reply":"2023-04-21T08:42:15.426024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = df9['ImgID'].unique()\nvalid_ids = image_ids[-4000:]\ntrain_ids = image_ids[:-4000]\nprint(len(train_ids), len(valid_ids))","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.428608Z","iopub.execute_input":"2023-04-21T08:42:15.429371Z","iopub.status.idle":"2023-04-21T08:42:15.444823Z","shell.execute_reply.started":"2023-04-21T08:42:15.4293Z","shell.execute_reply":"2023-04-21T08:42:15.443632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df = df9[df9['ImgID'].isin(valid_ids)]\ntrain_df = df9[df9['ImgID'].isin(train_ids)]\nprint(valid_df.shape, train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.448259Z","iopub.execute_input":"2023-04-21T08:42:15.448574Z","iopub.status.idle":"2023-04-21T08:42:15.469571Z","shell.execute_reply.started":"2023-04-21T08:42:15.448547Z","shell.execute_reply":"2023-04-21T08:42:15.468599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func(image):\n    Trgb2lms =np.array( [\n          np.array([17.8824, 43.5161, 4.1194]),\n          np.array([3.4557,27.1154, 3.8671]),\n          np.array([0.0300, 0.1843, 1.4671]) \n      ])\n    \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    x,y,z = image.shape\n#     print(image.shape)\n    cvd_due = np.array([\n                     np.array([1 ,0, 0]),   \n                     np.array([0.494207, 0, 1.24827]),   \n                     np.array([0, 0, 1]),   \n    ])\n    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n\n#     print(image.transpose(2, 0, 1).shape)\n    out = np.dot(INV_Trgb2lms, cvd_due)\n    out = np.dot(out, Trgb2lms)\n    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n    out = out.reshape(3,x,y).transpose(1, 2, 0)\n    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.472118Z","iopub.execute_input":"2023-04-21T08:42:15.472692Z","iopub.status.idle":"2023-04-21T08:42:15.482399Z","shell.execute_reply.started":"2023-04-21T08:42:15.472661Z","shell.execute_reply":"2023-04-21T08:42:15.480117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VOCDataset(Dataset):\n    \n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n        \n        self.image_ids = dataframe['ImgID'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n    \n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        records = self.df[self.df['ImgID'] == image_id]\n        \n        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = func(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        rows, cols = image.shape[:2]\n        \n        boxes = records[['XMin', 'YMin', 'XMax', 'YMax']].values\n        \n       \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n        \n        label = records['Label'].values\n        labels = torch.as_tensor(label, dtype=torch.int64)\n        \n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        # target['masks'] = None\n        target['image_id'] = torch.tensor([index])\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n        \n        if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n            \n            return image, target\n        \n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.484299Z","iopub.execute_input":"2023-04-21T08:42:15.485208Z","iopub.status.idle":"2023-04-21T08:42:15.498528Z","shell.execute_reply.started":"2023-04-21T08:42:15.485169Z","shell.execute_reply":"2023-04-21T08:42:15.49743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transform_train():\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.2),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n\ndef get_transform_valid():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.500412Z","iopub.execute_input":"2023-04-21T08:42:15.50088Z","iopub.status.idle":"2023-04-21T08:42:15.511548Z","shell.execute_reply.started":"2023-04-21T08:42:15.50084Z","shell.execute_reply":"2023-04-21T08:42:15.510586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\nIMG_PATH='/kaggle/working/test'\ntrain_dataset = VOCDataset(train_df, IMG_PATH , get_transform_train())\nvalid_dataset = VOCDataset(valid_df, IMG_PATH, get_transform_valid())\n\n\n# split the dataset in train and test set\nindices = torch.randperm(len(train_dataset)).tolist()\n\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.513179Z","iopub.execute_input":"2023-04-21T08:42:15.51392Z","iopub.status.idle":"2023-04-21T08:42:15.552484Z","shell.execute_reply.started":"2023-04-21T08:42:15.513877Z","shell.execute_reply":"2023-04-21T08:42:15.551368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.553998Z","iopub.execute_input":"2023-04-21T08:42:15.554641Z","iopub.status.idle":"2023-04-21T08:42:15.611776Z","shell.execute_reply.started":"2023-04-21T08:42:15.554593Z","shell.execute_reply":"2023-04-21T08:42:15.610095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes= {1:'Airplane', 2:'Bird', 3:'Drone', 4:'Helicopter'}\n\nimages, targets = next(iter(train_data_loader))\nimages = list(image.to(device) for image in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\nplt.figure(figsize=(20,20))\nfor i, (image, target) in enumerate(zip(images, targets)):\n    plt.subplot(2,2, i+1)\n    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n    sample = images[i].permute(1,2,0).cpu().numpy()\n    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n    for i,box in enumerate(boxes):\n        cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      (0, 0, 220), 2)\n        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n\n    plt.axis('off')\n    plt.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:15.620014Z","iopub.execute_input":"2023-04-21T08:42:15.622182Z","iopub.status.idle":"2023-04-21T08:42:22.215905Z","shell.execute_reply.started":"2023-04-21T08:42:15.622136Z","shell.execute_reply":"2023-04-21T08:42:22.214975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:22.217698Z","iopub.execute_input":"2023-04-21T08:42:22.218322Z","iopub.status.idle":"2023-04-21T08:42:25.427935Z","shell.execute_reply.started":"2023-04-21T08:42:22.21827Z","shell.execute_reply":"2023-04-21T08:42:25.426865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 5\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:25.429353Z","iopub.execute_input":"2023-04-21T08:42:25.429805Z","iopub.status.idle":"2023-04-21T08:42:25.437221Z","shell.execute_reply.started":"2023-04-21T08:42:25.429766Z","shell.execute_reply":"2023-04-21T08:42:25.436098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:25.438909Z","iopub.execute_input":"2023-04-21T08:42:25.439263Z","iopub.status.idle":"2023-04-21T08:42:25.503793Z","shell.execute_reply.started":"2023-04-21T08:42:25.439223Z","shell.execute_reply":"2023-04-21T08:42:25.502851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:25.505003Z","iopub.execute_input":"2023-04-21T08:42:25.50584Z","iopub.status.idle":"2023-04-21T08:42:45.678654Z","shell.execute_reply.started":"2023-04-21T08:42:25.505799Z","shell.execute_reply":"2023-04-21T08:42:45.67739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/pytorch/vision.git\n!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:42:45.680913Z","iopub.execute_input":"2023-04-21T08:42:45.681346Z","iopub.status.idle":"2023-04-21T08:44:11.705637Z","shell.execute_reply.started":"2023-04-21T08:42:45.681284Z","shell.execute_reply":"2023-04-21T08:44:11.704138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from engine import train_one_epoch, evaluate\nimport utils","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:44:11.707529Z","iopub.execute_input":"2023-04-21T08:44:11.707949Z","iopub.status.idle":"2023-04-21T08:44:11.737459Z","shell.execute_reply.started":"2023-04-21T08:44:11.707905Z","shell.execute_reply":"2023-04-21T08:44:11.736545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# let's train it for 2 epochs\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n    # train for one epoch, printing every 10 iterations\n    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n    # update the learning rate\n    lr_scheduler.step()\n    # evaluate on the test dataset\n    evaluate(model, valid_data_loader, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:44:11.73906Z","iopub.execute_input":"2023-04-21T08:44:11.739452Z","iopub.status.idle":"2023-04-21T11:05:13.926017Z","shell.execute_reply.started":"2023-04-21T08:44:11.739416Z","shell.execute_reply":"2023-04-21T11:05:13.924689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'FasterRCNNModel.pth')","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:13.92817Z","iopub.execute_input":"2023-04-21T11:05:13.928606Z","iopub.status.idle":"2023-04-21T11:05:14.219366Z","shell.execute_reply.started":"2023-04-21T11:05:13.928553Z","shell.execute_reply":"2023-04-21T11:05:14.218217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load  a model; pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n\nWEIGHTS_FILE = \"FasterRCNNModel.pth\"\n\nnum_classes = 5\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n# Load the traines weights\nmodel.load_state_dict(torch.load(WEIGHTS_FILE))\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:14.220865Z","iopub.execute_input":"2023-04-21T11:05:14.221886Z","iopub.status.idle":"2023-04-21T11:05:15.071353Z","shell.execute_reply.started":"2023-04-21T11:05:14.221828Z","shell.execute_reply":"2023-04-21T11:05:15.070189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def obj_detector(img):\n    img = cv2.imread(img, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n\n\n    img /= 255.0\n    img = torch.from_numpy(img)\n    img = img.unsqueeze(0)\n    img = img.permute(0,3,1,2)\n    \n    model.eval()\n\n    detection_threshold = 0.70\n    \n    img = list(im.to(device) for im in img)\n    output = model(img)\n\n    for i , im in enumerate(img):\n        boxes = output[i]['boxes'].data.cpu().numpy()\n        scores = output[i]['scores'].data.cpu().numpy()\n        labels = output[i]['labels'].data.cpu().numpy()\n\n        labels = labels[scores >= detection_threshold]\n        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n        scores = scores[scores >= detection_threshold]\n\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n    \n    sample = img[0].permute(1,2,0).cpu().numpy()\n    sample = np.array(sample)\n    boxes = output[0]['boxes'].data.cpu().numpy()\n    name = output[0]['labels'].data.cpu().numpy()\n    scores = output[0]['scores'].data.cpu().numpy()\n    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n    names = name.tolist()\n    \n    return names, boxes, sample, scores","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:15.072767Z","iopub.execute_input":"2023-04-21T11:05:15.073233Z","iopub.status.idle":"2023-04-21T11:05:15.08589Z","shell.execute_reply.started":"2023-04-21T11:05:15.073194Z","shell.execute_reply":"2023-04-21T11:05:15.084632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_path = \"/kaggle/input/samplepesu/Test_data_images\"\npred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n\nplt.figure(figsize=(20,60))\nfor i, images in enumerate(pred_files):\n    if i > 19:break\n    plt.subplot(10,2,i+1)\n    names,boxes,sample, score = obj_detector(images)\n    print(names, boxes, images, score)\n    for i,box in enumerate(boxes):\n        cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      (0, 220, 0), 2)\n        cv2.putText(sample, classes[names[i]], (box[0],box[1]-5),cv2.FONT_HERSHEY_COMPLEX ,0.7,(220,0,0),1,cv2.LINE_AA)  \n\n    plt.axis('off')\n    plt.imshow(sample)\n#     plt.savefig('save_image.png', bbox_inches='tight')  # if you want to save result","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:15.087574Z","iopub.execute_input":"2023-04-21T11:05:15.088067Z","iopub.status.idle":"2023-04-21T11:05:19.924757Z","shell.execute_reply.started":"2023-04-21T11:05:15.088028Z","shell.execute_reply":"2023-04-21T11:05:19.921425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:19.926387Z","iopub.execute_input":"2023-04-21T11:05:19.927082Z","iopub.status.idle":"2023-04-21T11:05:30.546137Z","shell.execute_reply.started":"2023-04-21T11:05:19.927043Z","shell.execute_reply":"2023-04-21T11:05:30.544656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:30.548446Z","iopub.execute_input":"2023-04-21T11:05:30.548874Z","iopub.status.idle":"2023-04-21T11:05:30.580419Z","shell.execute_reply.started":"2023-04-21T11:05:30.548825Z","shell.execute_reply":"2023-04-21T11:05:30.578217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9","metadata":{"execution":{"iopub.status.busy":"2023-04-21T11:05:30.582071Z","iopub.execute_input":"2023-04-21T11:05:30.582755Z","iopub.status.idle":"2023-04-21T11:05:30.605973Z","shell.execute_reply.started":"2023-04-21T11:05:30.582716Z","shell.execute_reply":"2023-04-21T11:05:30.605041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\npred_path = \"/kaggle/input/samplepesu/Test_data_images\"\npred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\ncsv_filename = 'object_detections.csv'\nmain_store = []\n#plt.figure(figsize=(20,60))\nfor i, images in enumerate(pred_files):\n#     if i > 96:break\n    #plt.subplot(10,2,i+1)\n    names,boxes,sample, score = obj_detector(images)\n    IMG = images.split('/')[-1]\n    print(len(names), len(boxes), images, len(score), IMG)\n    if(len(boxes) != 0):\n        main_store.append(\n            {\n                'ImageID': images,\n                'PredictionString': '{ ' + str(names[0]) + ' ' + str(round(score[0], 1)) + ' ' + str(boxes[0][0]) + ' ' + str(boxes[0][1]) + ' ' + str(boxes[0][2] - boxes[0][0]) + ' ' + str(boxes[0][3] - boxes[0][1]) + ' }',\n                ''\n            }\n        )\n    else:\n        main_store.append(\n            {\n                'ImageID': images,\n                'PredictionString': '{ ' + str(0) + ' ' + str(0) + ' ' + str(0) + ' ' + str(0) + ' ' + str(0) + ' ' + str(0) + ' }'\n            }\n        )\n    \n    #main_store.append([names, boxes, images, score])\n    # Create the CSV file and write the header row\n    '''\nimport csv\n\ncsv_filename = 'object_detections.csv'\n\nwith open(csv_filename, 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['Name', 'Box', 'Sample', 'Score'])\n\n    for i, image in enumerate(pred_files):\n        if i > 96:\n            break\n        \n        names, boxes, sample, score = obj_detector(image)\n\n        if len(names) > 0:\n            for j in range(len(names)):\n                writer.writerow([names[j], boxes[j], sample[j], score[j]])\n        else:\n            writer.writerow([None, None, None, None])'''\n\n\n    \n    \n    for i,box in enumerate(boxes):\n        cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      (0, 220, 0), 2)\n        cv2.putText(sample, classes[names[i]], (box[0],box[1]-5),cv2.FONT_HERSHEY_COMPLEX ,0.7,(220,0,0),1,cv2.LINE_AA)  \n\n    #plt.axis('off')\n    \n    #plt.imshow(sample)\n#     plt.savefig('save_image.png', bbox_inches='tight')  # if you want to save result","metadata":{"execution":{"iopub.status.busy":"2023-04-21T12:49:40.068251Z","iopub.execute_input":"2023-04-21T12:49:40.068596Z","iopub.status.idle":"2023-04-21T12:49:40.100524Z","shell.execute_reply.started":"2023-04-21T12:49:40.068564Z","shell.execute_reply":"2023-04-21T12:49:40.098905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}